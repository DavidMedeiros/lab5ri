{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab5 - RecInfo",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidMedeiros/lab5ri/blob/master/Lab5_RecInfo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-yrJ3Ptfvyf",
        "colab_type": "text"
      },
      "source": [
        "# Laboratório 5 - Expansão de Consultas\n",
        "## David de Medeiros Souza\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR2rRwifPysk",
        "colab_type": "code",
        "outputId": "d16c8283-29ee-4c69-f034-2e2c9c0fb89a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import numpy as np\n",
        "import collections\n",
        "from collections import Counter,OrderedDict\n",
        "import csv\n",
        "from tabulate import tabulate\n",
        "\n",
        "import time\n",
        "import heapq as hp\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import RSLPStemmer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('rslp')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdtE9miboDxO",
        "colab_type": "text"
      },
      "source": [
        "# Funções Auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDemRVtzoG1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Verifica se há numeros na string \n",
        "\"\"\"\n",
        "def hasNumbers(inputString):\n",
        "  return bool(re.search(r'\\d', inputString))\n",
        "\n",
        "\"\"\" \n",
        "  Retorna os documentos do indice como parametro\n",
        "\"\"\"\n",
        "def get_documents(index):\n",
        "  documents = []\n",
        "  \n",
        "  for _, inverted in index.items():\n",
        "      for document, _ in inverted.items():\n",
        "        documents.append(document)\n",
        "        \n",
        "  documents = list(set(documents))\n",
        "  \n",
        "  return documents\n",
        "\n",
        "  return bool(re.search(r'\\d', inputString))\n",
        "\n",
        "\"\"\" \n",
        "  Retorna a quantidade de documentos que term aparece\n",
        "\"\"\"\n",
        "def num_of_docs_of_term(term):\n",
        "    return len(index[term].keys())\n",
        "\n",
        "\"\"\" \n",
        "  Retorna a quantidade total de documentos\n",
        "\"\"\"\n",
        "def num_of_docs():\n",
        "  return csv['text'].count()\n",
        "\n",
        "\"\"\" \n",
        "  Retorna a quantidade de documentos que o term_a E o term_b aparecem\n",
        "\"\"\"\n",
        "def num_docs_intercessions(term_a,term_b):\n",
        "  docs1 = index[term_a].keys()\n",
        "  docs2 = index[term_b].keys()\n",
        "  counter = 0\n",
        "  \n",
        "  for doc in docs1:\n",
        "    if doc in docs2:\n",
        "      counter = counter + 1\n",
        "      \n",
        "  return counter\n",
        "\n",
        "\"\"\" \n",
        "  Retorna o valor de Mutual information (MIM) para o term_a e term_n\n",
        "\"\"\" \n",
        "def mutual_information(term_a, term_b):\n",
        "  n_a = num_of_docs_of_term(term_a)\n",
        "  n_b = num_of_docs_of_term(term_b)\n",
        "  n_ab = num_docs_intercessions(term_a, term_b) \n",
        "    \n",
        "  return ((n_ab) / (n_a * n_b))\n",
        "\n",
        "\n",
        "\"\"\" \n",
        "  Retorna o valor de Expected Mutual Information (EMIM) para o term_a e term_n\n",
        "\"\"\" \n",
        "def expected_mutual_information(term_a, term_b):\n",
        "  n_a = num_of_docs_of_term(term_a)\n",
        "  n_b = num_of_docs_of_term(term_b)\n",
        "  n_ab = num_docs_intercessions(term_a, term_b)\n",
        "  n = num_of_docs() \n",
        "  \n",
        "  if (n * ((n_ab) / (n_a * n_b))) == 0:\n",
        "    return 0\n",
        " \n",
        "  return n_ab * np.log(n * ((n_ab) / (n_a * n_b)))\n",
        "\n",
        "\"\"\" \n",
        "  Retorna o valor de Chi Square para o term_a e term_n\n",
        "\"\"\" \n",
        "def chi_square(term_a, term_b):\n",
        "  n_a = num_of_docs_of_term(term_a)\n",
        "  n_b = num_of_docs_of_term(term_b)\n",
        "  n_ab = num_docs_intercessions(term_a, term_b)\n",
        "  n = num_of_docs() \n",
        "  \n",
        "  return ((n_ab - (1/n) * n_a * n_b) ** 2) / (n_a * n_b)\n",
        "\n",
        "\"\"\" \n",
        "  Retorna o valor de Dice’s coefficient (Dice) para o term_a e term_n\n",
        "\"\"\" \n",
        "def dices_coefficient(term_a, term_b):\n",
        "  n_a = num_of_docs_of_term(term_a)\n",
        "  n_b = num_of_docs_of_term(term_b)\n",
        "  n_ab = num_docs_intercessions(term_a, term_b)\n",
        "    \n",
        "  return ((n_ab) / (n_a + n_b))\n",
        "\n",
        "\"\"\"\n",
        "  Retorna a lista ordenada (MIM) para uma determinada query\n",
        "\"\"\"\n",
        "def get_mim_list_ordered(query):\n",
        "  pairs = []\n",
        "  for termo in index.keys():\n",
        "    if termo != query:\n",
        "      mim_value = mutual_information(query, termo)\n",
        "      pairs.append((termo, mim_value))      \n",
        "  pairs = sorted(pairs, key = lambda x: x[1], reverse=True)\n",
        "  return pairs\n",
        "\n",
        "\"\"\"\n",
        "  Retorna a lista ordenada (EMIM) para uma determinada query\n",
        "\"\"\"\n",
        "def get_emim_list_ordered(query):\n",
        "  pairs = []\n",
        "  for termo in index.keys():\n",
        "    if termo != query:\n",
        "      emim_value = expected_mutual_information(query, termo)\n",
        "      pairs.append((termo, emim_value))      \n",
        "  pairs = sorted(pairs, key = lambda x: x[1], reverse=True)\n",
        "  return pairs\n",
        "\n",
        "\"\"\"\n",
        "  Retorna a lista ordenada (Chi-square) para uma determinada query\n",
        "\"\"\"\n",
        "def get_chisquare_list_ordered(query):\n",
        "  pairs = []\n",
        "  for termo in index.keys():\n",
        "    if termo != query:\n",
        "      chi_value = chi_square(query, termo)\n",
        "      pairs.append((termo, chi_value))      \n",
        "  pairs = sorted(pairs, key = lambda x: x[1], reverse=True)\n",
        "  return pairs\n",
        "\n",
        "\"\"\"\n",
        "  Retorna a lista ordenada (Dice) para uma determinada query\n",
        "\"\"\"\n",
        "def get_dice_list_ordered(query):\n",
        "  pairs = []\n",
        "  for termo in index.keys():\n",
        "    if termo != query:\n",
        "      dice_value = dices_coefficient(query, termo)\n",
        "      pairs.append((termo, dice_value))      \n",
        "  pairs = sorted(pairs, key = lambda x: x[1], reverse=True)\n",
        "  return pairs\n",
        "\n",
        "\"\"\"\n",
        "  Retorna uma tabela para query informada, com as top-10 palavras\n",
        "  mais associadas a cada delas de acordo com as métricas \n",
        "  MIM, EMIM, CHISQUARE e DICE.\n",
        "\"\"\"\n",
        "def set_table(query):\n",
        "  dataFrame = pandas.DataFrame()\n",
        "\n",
        "  dataFrame['MIM'] = [word for word, value in measure[query]['mim'][0:10]]  \n",
        "  dataFrame['EMIM'] = [word for word, value in measure[query]['emim'][0:10]] \n",
        "  dataFrame['X2'] = [word for word, value in measure[query]['chi-square'][0:10]]\n",
        "  dataFrame['Dice'] = [word for word, value in measure[query]['dice'][0:10]]\n",
        "  \n",
        "  return dataFrame.head(10)\n",
        "\n",
        "\"\"\"\n",
        "  Versão de consulta conjuntiva AND - Documentos por vez\n",
        "\"\"\"\n",
        "def conj_query(Q, I, k):\n",
        "  q_indexes = []\n",
        "  rank = []\n",
        "  \n",
        "  for word in Q.split(\" \"):\n",
        "    if word in I.keys():\n",
        "        q_indexes.append(I[word])\n",
        "  \n",
        "  all_indexes = [(k, item) for sublist in q_indexes for (k, item) in sublist.items()]\n",
        "  all_indexes = sorted(all_indexes, key = lambda x: x[0])\n",
        "  \n",
        "  for i in range(len(all_indexes)):\n",
        "    doc_score = 0\n",
        "    d,f = all_indexes.pop()\n",
        "    repeat = 1\n",
        "    for document, freq in all_indexes:\n",
        "      if document == d:\n",
        "        doc_score += freq\n",
        "        repeat += 1\n",
        "    if doc_score != 0 and repeat == len(q_indexes):\n",
        "      doc_score += f\n",
        "      hp.heappush(rank, (doc_score, d))\n",
        "  return [(d, sd) for sd, d in hp.nlargest(k, rank)]\n",
        "\n",
        "\"\"\"\n",
        "  Retorna a consulta expandida com os top number_of_top_terms de acordo com a métrica EMIM\n",
        "\"\"\"\n",
        "def get_expanded_query(query, number_of_top_terms):\n",
        "  top_results = [word for word, value in measure[query]['emim'][0:number_of_top_terms]]\n",
        "  result = query\n",
        "  for word in top_results:\n",
        "    result += \" \" + word\n",
        "    \n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJVNOBg7mzeq",
        "colab_type": "text"
      },
      "source": [
        "# Construção do índice \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2YPiDpxm2QZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_url = 'https://raw.githubusercontent.com/DavidMedeiros/ri_lab_01/master/output/results.csv'\n",
        "csv = pandas.read_csv(dataset_url)\n",
        "documents = csv['text']\n",
        "\n",
        "tokens = []\n",
        "tokens_filtered= []\n",
        "\n",
        "toker = RegexpTokenizer('''\\w+[-']*\\w*''')\n",
        "stopwords = stopwords.words(\"portuguese\")\n",
        "\n",
        "for document in documents:\n",
        "  tokens = tokens + toker.tokenize(document)\n",
        "\n",
        "\n",
        "def build_index(documents):\n",
        "  I = {}\n",
        "  n = 0\n",
        "  for document in documents:\n",
        "    n += 1\n",
        "    T = [token for token in toker.tokenize(document.lower())\n",
        "         if token not in stopwords and len(token) > 2 and not hasNumbers(token)]\n",
        "\n",
        "    for token in T:\n",
        "      if token not in I:\n",
        "        I[token] = {}\n",
        "      \n",
        "      ocurrence = T.count(token)\n",
        "      if n not in I[token]:\n",
        "        I[token][n] = ocurrence\n",
        "      \n",
        "  return I\n",
        "\n",
        "index = build_index(documents)\n",
        "\n",
        "data = {'token': list(index.keys()), 'ocurrences': list(index.values())}\n",
        "\n",
        "df = pandas.DataFrame(data)\n",
        "\n",
        "df.to_csv('index.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1LlLeO27Ljr",
        "colab_type": "text"
      },
      "source": [
        "# Questão 1\n",
        "\n",
        "Considerando as consultas de um termo somente, utilizadas no laboratório anterior: **\"ministro\", \"justiça\", \"bolsonaro\", \"lula\" e \"tribunal\"**, essa questão tem como objetivo a construção de uma tabela para cada consulta, informando as top-10 palavras mais associadas a cada delas de acordo com as métricas MIM, EMIM, CHISQUARE e DICE.\n",
        "\n",
        "Após visualizar as tabelas, acredito que **a métrica que obteve os melhores resultados foi a EMIM**, pois as top-10 palavras são mais promissoras e fazem mais sentido para cada uma das cinco consultas. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HmDsDG67ofP",
        "colab_type": "code",
        "outputId": "086f8cd5-fd04-4004-fa99-45835e1d1359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2227
        }
      },
      "source": [
        "queries = [\"ministro\", \"justiça\", \"bolsonaro\", \"lula\", \"tribunal\"]\n",
        "\n",
        "measure = {}\n",
        "  \n",
        "for query in queries:\n",
        "  querie_dict = {}\n",
        "  querie_dict['mim'] = get_mim_list_ordered(query)\n",
        "  querie_dict['emim'] = get_emim_list_ordered(query)\n",
        "  querie_dict['chi-square'] = get_chisquare_list_ordered(query)\n",
        "  querie_dict['dice'] = get_dice_list_ordered(query)\n",
        "  measure[query] = querie_dict\n",
        "  \n",
        "  df = set_table(query)\n",
        "  print(\"TABELA PARA CONSULTA: \" + query) \n",
        "  print(tabulate(df, headers='keys', tablefmt='fancy_grid'))\n",
        "  print(\"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TABELA PARA CONSULTA: ministro\n",
            "╒════╤════════════╤═════════╤════════════╤═════════╕\n",
            "│    │ MIM        │ EMIM    │ X2         │ Dice    │\n",
            "╞════╪════════════╪═════════╪════════════╪═════════╡\n",
            "│  0 │ perfil     │ desta   │ guedes     │ desta   │\n",
            "├────┼────────────┼─────────┼────────────┼─────────┤\n",
            "│  1 │ verificada │ federal │ desta      │ federal │\n",
            "├────┼────────────┼─────────┼────────────┼─────────┤\n",
            "│  2 │ poucas     │ guedes  │ ricardo    │ sobre   │\n",
            "├────┼────────────┼─────────┼────────────┼─────────┤\n",
            "│  3 │ provar     │ israel  │ publicação │ após    │\n",
            "├────┼────────────┼─────────┼────────────┼─────────┤\n",
            "│  4 │ postando   │ após    │ quanto     │ vai     │\n",
            "├────┼────────────┼─────────┼────────────┼─────────┤\n",
            "│  5 │ calendário │ sobre   │ israel     │ israel  │\n",
            "├────┼────────────┼─────────┼────────────┼─────────┤\n",
            "│  6 │ datando    │ ricardo │ rodriguez  │ paulo   │\n",
            "├────┼────────────┼─────────┼────────────┼─────────┤\n",
            "│  7 │ provando   │ oficial │ negócios   │ guedes  │\n",
            "├────┼────────────┼─────────┼────────────┼─────────┤\n",
            "│  8 │ inusitado  │ quanto  │ federal    │ brasil  │\n",
            "├────┼────────────┼─────────┼────────────┼─────────┤\n",
            "│  9 │ postagem   │ pública │ quatro     │ disse   │\n",
            "╘════╧════════════╧═════════╧════════════╧═════════╛\n",
            "\n",
            "\n",
            "TABELA PARA CONSULTA: justiça\n",
            "╒════╤════════════╤═══════════════╤══════════════╤═══════════════╕\n",
            "│    │ MIM        │ EMIM          │ X2           │ Dice          │\n",
            "╞════╪════════════╪═══════════════╪══════════════╪═══════════════╡\n",
            "│  0 │ perfil     │ público       │ comissão     │ público       │\n",
            "├────┼────────────┼───────────────┼──────────────┼───────────────┤\n",
            "│  1 │ verificada │ tribunal      │ tribunal     │ tribunal      │\n",
            "├────┼────────────┼───────────────┼──────────────┼───────────────┤\n",
            "│  2 │ poucas     │ pública       │ pública      │ pública       │\n",
            "├────┼────────────┼───────────────┼──────────────┼───────────────┤\n",
            "│  3 │ provar     │ constituição  │ público      │ constituição  │\n",
            "├────┼────────────┼───────────────┼──────────────┼───────────────┤\n",
            "│  4 │ postando   │ comissão      │ segurança    │ comissão      │\n",
            "├────┼────────────┼───────────────┼──────────────┼───────────────┤\n",
            "│  5 │ calendário │ segurança     │ constituição │ segurança     │\n",
            "├────┼────────────┼───────────────┼──────────────┼───────────────┤\n",
            "│  6 │ datando    │ ex-presidente │ sérgio       │ ex-presidente │\n",
            "├────┼────────────┼───────────────┼──────────────┼───────────────┤\n",
            "│  7 │ provando   │ abril         │ papel        │ abril         │\n",
            "├────┼────────────┼───────────────┼──────────────┼───────────────┤\n",
            "│  8 │ inusitado  │ decisão       │ reparação    │ decisão       │\n",
            "├────┼────────────┼───────────────┼──────────────┼───────────────┤\n",
            "│  9 │ tacla      │ moro          │ ccj          │ deputado      │\n",
            "╘════╧════════════╧═══════════════╧══════════════╧═══════════════╛\n",
            "\n",
            "\n",
            "TABELA PARA CONSULTA: bolsonaro\n",
            "╒════╤═════════════╤════════════╤══════════════╤════════════╕\n",
            "│    │ MIM         │ EMIM       │ X2           │ Dice       │\n",
            "╞════╪═════════════╪════════════╪══════════════╪════════════╡\n",
            "│  0 │ comunicar   │ jair       │ jair         │ jair       │\n",
            "├────┼─────────────┼────────────┼──────────────┼────────────┤\n",
            "│  1 │ diretamente │ presidente │ presidente   │ presidente │\n",
            "├────┼─────────────┼────────────┼──────────────┼────────────┤\n",
            "│  2 │ certa       │ governo    │ desde        │ governo    │\n",
            "├────┼─────────────┼────────────┼──────────────┼────────────┤\n",
            "│  3 │ driblar     │ leia       │ psl          │ brasil     │\n",
            "├────┼─────────────┼────────────┼──────────────┼────────────┤\n",
            "│  4 │ aderiu      │ anos       │ visita       │ disse      │\n",
            "├────┼─────────────┼────────────┼──────────────┼────────────┤\n",
            "│  5 │ plataforma  │ psl        │ problemas    │ contra     │\n",
            "├────┼─────────────┼────────────┼──────────────┼────────────┤\n",
            "│  6 │ preferida   │ entrevista │ investigação │ segundo    │\n",
            "├────┼─────────────┼────────────┼──────────────┼────────────┤\n",
            "│  7 │ jair        │ então      │ porta-voz    │ anos       │\n",
            "├────┼─────────────┼────────────┼──────────────┼────────────┤\n",
            "│  8 │ resolvi     │ visita     │ leia         │ diz        │\n",
            "├────┼─────────────┼────────────┼──────────────┼────────────┤\n",
            "│  9 │ aderir      │ problemas  │ entrevista   │ ser        │\n",
            "╘════╧═════════════╧════════════╧══════════════╧════════════╛\n",
            "\n",
            "\n",
            "TABELA PARA CONSULTA: lula\n",
            "╒════╤════════════╤═══════════════╤═══════════════╤═══════════════╕\n",
            "│    │ MIM        │ EMIM          │ X2            │ Dice          │\n",
            "╞════╪════════════╪═══════════════╪═══════════════╪═══════════════╡\n",
            "│  0 │ sergio     │ ex-presidente │ ex-presidente │ ex-presidente │\n",
            "├────┼────────────┼───────────────┼───────────────┼───────────────┤\n",
            "│  1 │ perfil     │ luiz          │ inácio        │ luiz          │\n",
            "├────┼────────────┼───────────────┼───────────────┼───────────────┤\n",
            "│  2 │ verificada │ inácio        │ silva         │ inácio        │\n",
            "├────┼────────────┼───────────────┼───────────────┼───────────────┤\n",
            "│  3 │ poucas     │ silva         │ luiz          │ silva         │\n",
            "├────┼────────────┼───────────────┼───────────────┼───────────────┤\n",
            "│  4 │ provar     │ prisão        │ prisão        │ prisão        │\n",
            "├────┼────────────┼───────────────┼───────────────┼───────────────┤\n",
            "│  5 │ postando   │ abril         │ condenação    │ abril         │\n",
            "├────┼────────────┼───────────────┼───────────────┼───────────────┤\n",
            "│  6 │ calendário │ curitiba      │ guarujá       │ processo      │\n",
            "├────┼────────────┼───────────────┼───────────────┼───────────────┤\n",
            "│  7 │ datando    │ processo      │ julgamento    │ curitiba      │\n",
            "├────┼────────────┼───────────────┼───────────────┼───────────────┤\n",
            "│  8 │ provando   │ rede          │ advogados     │ psl           │\n",
            "├────┼────────────┼───────────────┼───────────────┼───────────────┤\n",
            "│  9 │ inusitado  │ psl           │ curitiba      │ rede          │\n",
            "╘════╧════════════╧═══════════════╧═══════════════╧═══════════════╛\n",
            "\n",
            "\n",
            "TABELA PARA CONSULTA: tribunal\n",
            "╒════╤═════════════╤══════════════╤════════════╤══════════════╕\n",
            "│    │ MIM         │ EMIM         │ X2         │ Dice         │\n",
            "╞════╪═════════════╪══════════════╪════════════╪══════════════╡\n",
            "│  0 │ solicitando │ supremo      │ supremo    │ supremo      │\n",
            "├────┼─────────────┼──────────────┼────────────┼──────────────┤\n",
            "│  1 │ tríplex     │ justiça      │ julgamento │ justiça      │\n",
            "├────┼─────────────┼──────────────┼────────────┼──────────────┤\n",
            "│  2 │ julgado     │ lei          │ petrobrás  │ lei          │\n",
            "├────┼─────────────┼──────────────┼────────────┼──────────────┤\n",
            "│  3 │ breve       │ decisão      │ papel      │ julgamento   │\n",
            "├────┼─────────────┼──────────────┼────────────┼──────────────┤\n",
            "│  4 │ apreciado   │ julgamento   │ âmbito     │ stf          │\n",
            "├────┼─────────────┼──────────────┼────────────┼──────────────┤\n",
            "│  5 │ visa        │ processo     │ stf        │ decisão      │\n",
            "├────┼─────────────┼──────────────┼────────────┼──────────────┤\n",
            "│  6 │ anular      │ constituição │ justiça    │ processo     │\n",
            "├────┼─────────────┼──────────────┼────────────┼──────────────┤\n",
            "│  7 │ stj         │ stf          │ lei        │ constituição │\n",
            "├────┼─────────────┼──────────────┼────────────┼──────────────┤\n",
            "│  8 │ felix       │ desta        │ documento  │ desta        │\n",
            "├────┼─────────────┼──────────────┼────────────┼──────────────┤\n",
            "│  9 │ fischer     │ documento    │ relator    │ documento    │\n",
            "╘════╧═════════════╧══════════════╧════════════╧══════════════╛\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVuOe3siXoej",
        "colab_type": "text"
      },
      "source": [
        "# Questão 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hUKNfLopW3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documents_results = {}\n",
        "expanded_querys = {}\n",
        "\n",
        "for top_k in [3, 5, 10]:\n",
        "  for query in queries:\n",
        "    expanded_query = get_expanded_query(query, top_k)\n",
        "    documents = conj_query(expanded_query, index, 10)\n",
        "    \n",
        "    if query not in documents_results.keys():\n",
        "      documents_results[query] = [documents]\n",
        "      expanded_querys[query] = [expanded_query]\n",
        "    else:\n",
        "      documents_results[query].append(documents)\n",
        "      expanded_querys[query].append(expanded_query)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLUU6lCEehWd",
        "colab_type": "code",
        "outputId": "c5973652-5bd0-40a5-9d0c-0702a6ed3ecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "pandas.options.display.max_colwidth = 160\n",
        "\n",
        "data_frame_conj = pandas.DataFrame()\n",
        "data_frame_conj['Top k'] = ['3','5','10'] * 3\n",
        "data_frame_conj['Consulta expandida'] = expanded_querys[queries[0]] + expanded_querys[queries[1]] + expanded_querys[queries[2]]\n",
        "data_frame_conj['Documentos'] = documents_results[queries[0]] + documents_results[queries[1]] + documents_results[queries[2]]\n",
        "  \n",
        "print(tabulate(data_frame_conj, headers='keys', tablefmt='fancy_grid'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "╒════╤═════════╤═══════════════════════════════════════════════════════════════════════════════════════════════════╤════════════════════════════════════════════════════════════════════════════════════════════════════╕\n",
            "│    │   Top k │ Consulta expandida                                                                                │ Documentos                                                                                         │\n",
            "╞════╪═════════╪═══════════════════════════════════════════════════════════════════════════════════════════════════╪════════════════════════════════════════════════════════════════════════════════════════════════════╡\n",
            "│  0 │       3 │ ministro desta federal guedes                                                                     │ [(69, 17)]                                                                                         │\n",
            "├────┼─────────┼───────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│  1 │       5 │ ministro desta federal guedes israel após                                                         │ [(69, 19)]                                                                                         │\n",
            "├────┼─────────┼───────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│  2 │      10 │ ministro desta federal guedes israel após sobre ricardo oficial quanto pública                    │ []                                                                                                 │\n",
            "├────┼─────────┼───────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│  3 │       3 │ justiça público tribunal pública                                                                  │ [(25, 6), (105, 4)]                                                                                │\n",
            "├────┼─────────┼───────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│  4 │       5 │ justiça público tribunal pública constituição comissão                                            │ [(105, 9)]                                                                                         │\n",
            "├────┼─────────┼───────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│  5 │      10 │ justiça público tribunal pública constituição comissão segurança ex-presidente abril decisão moro │ []                                                                                                 │\n",
            "├────┼─────────┼───────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│  6 │       3 │ bolsonaro jair presidente governo                                                                 │ [(87, 20), (77, 19), (83, 13), (81, 13), (85, 12), (13, 12), (38, 11), (5, 11), (32, 10), (73, 9)] │\n",
            "├────┼─────────┼───────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│  7 │       5 │ bolsonaro jair presidente governo leia anos                                                       │ [(77, 27), (87, 22), (81, 16), (32, 12)]                                                           │\n",
            "├────┼─────────┼───────────────────────────────────────────────────────────────────────────────────────────────────┼────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│  8 │      10 │ bolsonaro jair presidente governo leia anos psl entrevista então visita problemas                 │ []                                                                                                 │\n",
            "╘════╧═════════╧═══════════════════════════════════════════════════════════════════════════════════════════════════╧════════════════════════════════════════════════════════════════════════════════════════════════════╛\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}